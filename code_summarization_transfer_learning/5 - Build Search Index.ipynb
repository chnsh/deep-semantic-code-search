{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "\n",
    "You should have completed steps 1-4 of this tutorial before beginning this exercise.  The files required for this notebook are generated by those previous steps.\n",
    "\n",
    "Creating the search engine for this example is extremely CPU and memory intensive.  We used an an AWS `x1.32xlarge` instance (128 cores) in order to achieve the maximum speed with building the search index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import nmslib\n",
    "from lang_model_utils import load_lm_vocab, Query2Emb\n",
    "from general_utils import create_nmslib_search_index\n",
    "\n",
    "input_path = Path('./data/processed_data/')\n",
    "code2emb_path = Path('./data/code2emb/')\n",
    "output_path = Path('./data/search')\n",
    "output_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Metadata\n",
    "\n",
    "We will want to organize the data that we will want to display for the search results, which will be:\n",
    "\n",
    "1. The original code\n",
    "2. A link to the original code\n",
    "\n",
    "For convenience, we will collect this data into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_pickle('dataframe_processed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def listlen(x):\n",
    "    if not isinstance(x, list):\n",
    "        return 0\n",
    "    return len(x)\n",
    "\n",
    "# separate functions w/o docstrings\n",
    "# docstrings should be at least 3 words in the docstring to be considered a valid docstring\n",
    "\n",
    "with_docstrings = df[df.docstring_tokens.str.split().apply(listlen) >= 3]\n",
    "without_docstrings = df[df.docstring_tokens.str.split().apply(listlen) < 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file of code\n",
    "ref_df = without_docstrings['original_function']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Search Index For Vectorized Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First read in the vectorized code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodoc_vecs = np.load('./data/code2emb/nodoc_vecs.npy')\n",
    "assert nodoc_vecs.shape[0] == ref_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now build the search index. **Warning:** this step takes ~ 18 minutes on an `x1.32xlarge` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_index = create_nmslib_search_index(nodoc_vecs)\n",
    "search_index.saveIndex('./data/search/search_index.nmslib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cached version of this index can be downloaded here:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create A Minimal Search Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Loaded vocab of size 24,902\n",
      "WARNING:root:Processing 1 rows\n"
     ]
    }
   ],
   "source": [
    "lang_model = torch.load('./data/lang_model/lang_model_cpu_v2.torch', \n",
    "                        map_location=lambda storage, loc: storage)\n",
    "\n",
    "vocab = load_lm_vocab('./data/lang_model/vocab_v2.cls')\n",
    "q2emb = Query2Emb(lang_model = lang_model.cpu(),\n",
    "                  vocab = vocab)\n",
    "\n",
    "search_index = nmslib.init(method='hnsw', space='cosinesimil')\n",
    "search_index.loadIndex('./data/search/search_index.nmslib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Query2Emb` is a helper class that will vectorize sentences using the language model trained in Part 3.  \n",
    "\n",
    "In this case, we call the method `emb_mean` because we are taking the mean over the time steps of the hidden states in order to construct a sentence embedding for the query supplied by the user.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Processing 1 rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 500)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = q2emb.emb_mean('Hello World!  This is a test.')\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an object to make the process of showing search results easier\n",
    "\n",
    "The below object organizes all the pieces together for searching the index and displaying the results with a method call.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class search_engine:\n",
    "    \"\"\"Organizes all the necessary elements we need to make a search engine.\"\"\"\n",
    "    def __init__(self, \n",
    "                 nmslib_index, \n",
    "                 ref_df, \n",
    "                 query2emb_func):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ==========\n",
    "        nmslib_index : nmslib object\n",
    "            This is pre-computed search index.\n",
    "        ref_df : pandas.DataFrame\n",
    "            This dataframe contains meta-data for search results, \n",
    "            must contain the columns 'code' and 'url'.\n",
    "        query2emb_func : callable\n",
    "            This is a function that takes as input a string and returns a vector\n",
    "            that is in the same vector space as what is loaded into the search index.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        self.search_index = nmslib_index\n",
    "        self.ref_df = ref_df\n",
    "        self.query2emb_func = query2emb_func\n",
    "    \n",
    "    def search(self, str_search, k=5):\n",
    "        \"\"\"\n",
    "        Prints the code that are the nearest neighbors (by cosine distance)\n",
    "        to the search query.\n",
    "        \n",
    "        Parameters\n",
    "        ==========\n",
    "        str_search : str\n",
    "            a search query.  Ex: \"read data into pandas dataframe\"\n",
    "        k : int\n",
    "            the number of nearest neighbors to return.  Defaults to 2.\n",
    "        \n",
    "        \"\"\"\n",
    "        query = self.query2emb_func(str_search)\n",
    "        idxs, dists = self.search_index.knnQuery(query, k=k)\n",
    "        \n",
    "        for idx, dist in zip(idxs, dists):\n",
    "            code = self.ref_df.iloc[idx]\n",
    "            print(f'cosine dist:{dist:.4f} \\n---------------\\n')\n",
    "            print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "se = search_engine(nmslib_index=search_index,\n",
    "                   ref_df=ref_df,\n",
    "                   query2emb_func=q2emb.emb_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Some Queries Against The Index!!\n",
    "\n",
    "Now that we have instantiated the search engine, we can use the `search` method to display the results.\n",
    "\n",
    "**Warning:** some of the displayed links may not work since this is historical data retrieved from a [historical open dataset Google has hosted on BigQuery](https://cloud.google.com/bigquery/public-data/github)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Processing 1 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine dist:0.1352 \n",
      "---------------\n",
      "\n",
      "def plot_1d(self, f, a, b, grid_size=1000):\n",
      "    grid = np.linspace(a, b, num=grid_size).reshape((-1, 1))\n",
      "    mu, sigma = self.utility.mean_and_std(grid)\n",
      "    plt.plot(grid, f(grid), color='black', linewidth=1.5, label='f')\n",
      "    plt.plot(grid, mu, color='red', label='mu')\n",
      "    plt.plot(grid, mu + sigma, color='blue', linewidth=0.4, label='mu+sigma')\n",
      "    plt.plot(grid, mu - sigma, color='blue', linewidth=0.4)\n",
      "    plt.plot(self.points, f(np.asarray(self.points)), 'o', color='red')\n",
      "    plt.xlim([a - 0.5, b + 0.5])\n",
      "    plt.show()\n",
      "\n",
      "cosine dist:0.1357 \n",
      "---------------\n",
      "\n",
      "def plotIQ(data, Fs):\n",
      "    if Fs == None:\n",
      "        plt.plot(np.real(data), label='I')\n",
      "        plt.plot(np.imag(data), label='Q')\n",
      "    else:\n",
      "        plt.plot(np.real(data), label='I')\n",
      "        plt.plot(np.imag(data), label='Q')\n",
      "    plt.grid(True)\n",
      "    plt.legend(loc='upper right', frameon=True)\n",
      "    plt.show()\n",
      "\n",
      "cosine dist:0.1366 \n",
      "---------------\n",
      "\n",
      "def plot_butterfly(evoked, ax=None, sig=None, color=None, ch_type=None):\n",
      "    from mne import pick_types\n",
      "    if ch_type is not None:\n",
      "        picks = pick_types(evoked.info, ch_type)\n",
      "        evoked = evoked.copy()\n",
      "        evoked = evoked.pick_types(ch_type)\n",
      "        sig = sig[(picks), :] if sig is not None else None\n",
      "    times = evoked.times * 1000.0\n",
      "    data = evoked.data\n",
      "    ax = plt.gca() if ax is None else ax\n",
      "    ax.plot(times, data.T, color='k', alpha=0.5)\n",
      "    gfp = np.vstack((data.max(0), data.min(0)))\n",
      "    if sig is not None:\n",
      "        sig = np.array(np.sum(sig, axis=0) > 0.0, dtype=int)\n",
      "        ax.fill_between(np.hstack((times, times[::-1])), np.hstack((sig *\n",
      "            gfp[(0), :] + (1 - sig) * gfp[(1), :], gfp[(1), ::-1])),\n",
      "            facecolor=color, edgecolor='none', alpha=0.5, zorder=len(data) + 1)\n",
      "    ax.axvline(0, color='k')\n",
      "    ax.set_xlabel('Times (ms)')\n",
      "    ax.set_xlim(min(times), max(times))\n",
      "    xticks = np.arange(np.ceil(min(times) / 100.0) * 100.0, np.floor(max(\n",
      "        times) / 100.0) * 100.0 + 1e-10, 100)\n",
      "    ax.set_xticks(xticks)\n",
      "    ax.set_xticklabels([('%i' % t if t in [xticks[0], xticks[-1], 0] else\n",
      "        '') for t in xticks])\n",
      "    ax.set_yticks([np.min(data), np.max(data)])\n",
      "    ax.set_ylim(np.min(data), np.max(data))\n",
      "    ax.set_xlim(np.min(times), np.max(times))\n",
      "    pretty_plot(ax)\n",
      "    return ax\n",
      "\n",
      "cosine dist:0.1374 \n",
      "---------------\n",
      "\n",
      "def _plot_component(factors, idx, ax=None, cal_axis=None, comp_label='PC'):\n",
      "    if ax is None:\n",
      "        ax = plt.gca()\n",
      "    if cal_axis is not None:\n",
      "        x = cal_axis.axis\n",
      "        plt.xlabel(cal_axis.units)\n",
      "    else:\n",
      "        x = np.arange(factors.shape[0])\n",
      "        plt.xlabel('Channel index')\n",
      "    ax.plot(x, factors[:, (idx)], label='%s %i' % (comp_label, idx))\n",
      "    return ax\n",
      "\n",
      "cosine dist:0.1376 \n",
      "---------------\n",
      "\n",
      "def plot_gfp(evoked, ax=None, sig=None, color=None, ch_type='mag'):\n",
      "    from mne import pick_types\n",
      "    if ch_type is not None:\n",
      "        picks = pick_types(evoked.info, ch_type)\n",
      "        evoked = evoked.copy()\n",
      "        evoked = evoked.pick_types(ch_type)\n",
      "        sig = sig[(picks), :] if sig is not None else None\n",
      "    times = evoked.times * 1000.0\n",
      "    gfp = np.std(evoked.data, axis=0)\n",
      "    ax = plt.gca() if ax is None else ax\n",
      "    ax.plot(times, gfp, color='k', alpha=0.5)\n",
      "    if sig is not None:\n",
      "        sig = np.array(np.sum(sig, axis=0) > 0.0, dtype=int)\n",
      "        ax.fill_between(np.hstack((times, times[::-1])), np.hstack((sig *\n",
      "            gfp, np.zeros_like(gfp))), facecolor=color, edgecolor='none',\n",
      "            alpha=0.5)\n",
      "    ax.axvline(0, color='k')\n",
      "    ax.set_xlabel('Times (ms)')\n",
      "    ax.set_xlim(min(times), max(times))\n",
      "    xticks = np.arange(np.ceil(min(times) / 100.0) * 100.0, np.floor(max(\n",
      "        times) / 100.0) * 100.0 + 1e-10, 100)\n",
      "    ax.set_xticks(xticks)\n",
      "    ax.set_xticklabels([('%i' % t if t in [xticks[0], xticks[-1], 0] else\n",
      "        '') for t in xticks])\n",
      "    ax.set_yticks([np.min(gfp), np.max(gfp)])\n",
      "    ax.set_ylim(np.min(gfp), np.max(gfp))\n",
      "    ax.set_xlim(np.min(times), np.max(times))\n",
      "    pretty_plot(ax)\n",
      "    return ax\n",
      "\n"
     ]
    }
   ],
   "source": [
    "se.search('plot 3d gaussian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import (register_line_magic, register_cell_magic,\n",
    "                                register_line_cell_magic)\n",
    "@register_cell_magic\n",
    "def search(line, cell):\n",
    "    return se.search(cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Live Semantic Search of Code (Searching Holdout Set Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Processing 1 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine dist:0.1974 \n",
      "---------------\n",
      "\n",
      "def traverse(self, root):\n",
      "    self.worklist = []\n",
      "    self.__run(root)\n",
      "\n",
      "cosine dist:0.2037 \n",
      "---------------\n",
      "\n",
      "def traverse_tree(self, name, cat='pre'):\n",
      "    base = self.data[cat]['roles'][name]\n",
      "    base_tree = base['tree']\n",
      "    role_keys = base_tree.keys()\n",
      "    self.traverse_print_tree(base_tree, role_keys)\n",
      "\n",
      "cosine dist:0.2062 \n",
      "---------------\n",
      "\n",
      "def traverse(self):\n",
      "    self.initialize()\n",
      "    self.path = deque()\n",
      "    self.astar_traverse(None)\n",
      "    self.form_path()\n",
      "    return list(self.path), self.steps\n",
      "\n",
      "cosine dist:0.2091 \n",
      "---------------\n",
      "\n",
      "def walk(dag, walk_func):\n",
      "    return dag.walk(walk_func)\n",
      "\n",
      "cosine dist:0.2107 \n",
      "---------------\n",
      "\n",
      "def walk(self):\n",
      "    return self.walk_preorder()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%search\n",
    "traverse a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

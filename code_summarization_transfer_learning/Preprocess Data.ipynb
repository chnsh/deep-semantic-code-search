{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "Most of what has been done for the transfer learning model has been borrowed from these notebooks and we have trained our joint embedding model by reusing most of the code provided by them.\n",
        "\n",
        "The source of this excellent article can be found here: [How To Create Natural Language Semantic Search For Arbitrary Objects With Deep Learning](https://towardsdatascience.com/semantic-code-search-3cd6d244a39c)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "# Preprocess Data\n",
        "This notebook contains materials to parse raw python files into function and docstring pairs, tokenize both function and dosctring into tokens, and split these pairs into a train, valid and test set.  \n",
        "\n",
        "If you are using the recommended approach of using a `p3.8xlarge` instance for this entire tutorial you can use this docker container to run this notebook: [hamelsmu/ml-gpu](https://hub.docker.com/r/hamelsmu/ml-gpu/).\n",
        "\n",
        "Alternatively, if you wish to speed up *this notebook* by using an instance with lots of cores (because everything in this notebook is CPU bound), you can use this container [hamelsmu/ml-cpu](https://hub.docker.com/r/hamelsmu/ml-gpu/).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  return f(*args, **kwds)\n",
            "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
            "  return f(*args, **kwds)\n",
            "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  return f(*args, **kwds)\n",
            "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
            "  return f(*args, **kwds)\n",
            "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  return f(*args, **kwds)\n",
            "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  return f(*args, **kwds)\n",
            "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
            "  return f(*args, **kwds)\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# EN \u003d spacy.load(\u0027en_core_web_sm\u0027)\n",
        "import en_core_web_sm\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from general_utils import apply_parallel, flattenlist\n",
        "EN \u003d en_core_web_sm.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/ds/notebooks\r\n"
          ]
        }
      ],
      "source": [
        "! pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Download and read  raw python files\n",
        "\n",
        "The first thing we will want to do is to gather python code.  There is an open dataset that Google hosts on [BigQuery](https://cloud.google.com/bigquery/) that has code from open source projects on Github.  You can use [bigquery](https://cloud.google.com/bigquery/) to get the python files as a tabular dataset by executing the following SQL query in the bigquery console:\n",
        "\n",
        "```{sql}\n",
        "SELECT \n",
        " max(concat(f.repo_name, \u0027 \u0027, f.path)) as repo_path,\n",
        " c.content\n",
        "FROM `bigquery-public-data.github_repos.files` as f\n",
        "JOIN `bigquery-public-data.github_repos.contents` as c on f.id \u003d c.id\n",
        "JOIN (\n",
        "      --this part of the query makes sure repo is watched at least twice since 2017\n",
        "      SELECT repo FROM(\n",
        "        SELECT \n",
        "          repo.name as repo\n",
        "        FROM `githubarchive.year.2017` WHERE type\u003d\"WatchEvent\"\n",
        "        UNION ALL\n",
        "        SELECT \n",
        "          repo.name as repo\n",
        "        FROM `githubarchive.month.2018*` WHERE type\u003d\"WatchEvent\"\n",
        "        )\n",
        "      GROUP BY 1\n",
        "      HAVING COUNT(*) \u003e\u003d 2\n",
        "      ) as r on f.repo_name \u003d r.repo\n",
        "WHERE \n",
        "  f.path like \u0027%.py\u0027 and --with python extension\n",
        "  c.size \u003c 15000 and --get rid of ridiculously long files\n",
        "  REGEXP_CONTAINS(c.content, r\u0027def \u0027) --contains function definition\n",
        "group by c.content\n",
        "```\n",
        "\n",
        "\n",
        "Here is a link to the [SQL Query](https://bigquery.cloud.google.com/savedquery/506213277345:009fa66f301240e5ad9e4006c59a4762) incase it is helpful.  The raw data contains approximate 1.2 million distinct python code files.\n",
        "\n",
        "**To make things easier for this tutorial, the folks on the Google [Kubeflow team](https://kubernetes.io/blog/2017/12/introducing-kubeflow-composable/) have hosted the raw data for this tutorial in the form of 10 csv files, available at the url: https://storage.googleapis.com/kubeflow-examples/code_search/raw_data/00000000000{i}.csv as illustrated in the below code:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\u003cdiv\u003e\n",
              "\u003cstyle scoped\u003e\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\u003c/style\u003e\n",
              "\u003ctable border\u003d\"1\" class\u003d\"dataframe\"\u003e\n",
              "  \u003cthead\u003e\n",
              "    \u003ctr style\u003d\"text-align: right;\"\u003e\n",
              "      \u003cth\u003e\u003c/th\u003e\n",
              "      \u003cth\u003enwo\u003c/th\u003e\n",
              "      \u003cth\u003epath\u003c/th\u003e\n",
              "      \u003cth\u003econtent\u003c/th\u003e\n",
              "    \u003c/tr\u003e\n",
              "  \u003c/thead\u003e\n",
              "  \u003ctbody\u003e\n",
              "    \u003ctr\u003e\n",
              "      \u003cth\u003e0\u003c/th\u003e\n",
              "      \u003ctd\u003efnl/libfnl\u003c/td\u003e\n",
              "      \u003ctd\u003esrc/fnl/nlp/dictionary.py\u003c/td\u003e\n",
              "      \u003ctd\u003e\"\"\"\\n.. py:module:: fnl.text.dictionary\\n   :s...\u003c/td\u003e\n",
              "    \u003c/tr\u003e\n",
              "    \u003ctr\u003e\n",
              "      \u003cth\u003e1\u003c/th\u003e\n",
              "      \u003ctd\u003eKivApple/mcu-info-util\u003c/td\u003e\n",
              "      \u003ctd\u003emcu_info_util/linker_script.py\u003c/td\u003e\n",
              "      \u003ctd\u003efrom six import iteritems\\n\\n\\ndef generate(op...\u003c/td\u003e\n",
              "    \u003c/tr\u003e\n",
              "    \u003ctr\u003e\n",
              "      \u003cth\u003e2\u003c/th\u003e\n",
              "      \u003ctd\u003eYelp/pyleus\u003c/td\u003e\n",
              "      \u003ctd\u003eexamples/bandwith_monitoring/bandwith_monitori...\u003c/td\u003e\n",
              "      \u003ctd\u003efrom __future__ import absolute_import, divisi...\u003c/td\u003e\n",
              "    \u003c/tr\u003e\n",
              "    \u003ctr\u003e\n",
              "      \u003cth\u003e3\u003c/th\u003e\n",
              "      \u003ctd\u003ejhuapl-boss/boss-manage\u003c/td\u003e\n",
              "      \u003ctd\u003ebin/bearer_token.py\u003c/td\u003e\n",
              "      \u003ctd\u003e#!/usr/bin/env python3\\n\\n# Copyright 2016 The...\u003c/td\u003e\n",
              "    \u003c/tr\u003e\n",
              "    \u003ctr\u003e\n",
              "      \u003cth\u003e4\u003c/th\u003e\n",
              "      \u003ctd\u003edjfroofy/beatlounge\u003c/td\u003e\n",
              "      \u003ctd\u003ebl/orchestra/base.py\u003c/td\u003e\n",
              "      \u003ctd\u003efrom itertools import cycle\\n\\nfrom twisted.py...\u003c/td\u003e\n",
              "    \u003c/tr\u003e\n",
              "  \u003c/tbody\u003e\n",
              "\u003c/table\u003e\n",
              "\u003c/div\u003e"
            ],
            "text/plain": [
              "                       nwo                                               path  \\\n",
              "0               fnl/libfnl                          src/fnl/nlp/dictionary.py   \n",
              "1   KivApple/mcu-info-util                     mcu_info_util/linker_script.py   \n",
              "2              Yelp/pyleus  examples/bandwith_monitoring/bandwith_monitori...   \n",
              "3  jhuapl-boss/boss-manage                                bin/bearer_token.py   \n",
              "4      djfroofy/beatlounge                               bl/orchestra/base.py   \n",
              "\n",
              "                                             content  \n",
              "0  \"\"\"\\n.. py:module:: fnl.text.dictionary\\n   :s...  \n",
              "1  from six import iteritems\\n\\n\\ndef generate(op...  \n",
              "2  from __future__ import absolute_import, divisi...  \n",
              "3  #!/usr/bin/env python3\\n\\n# Copyright 2016 The...  \n",
              "4  from itertools import cycle\\n\\nfrom twisted.py...  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Read the data into a pandas dataframe, and parse out some meta-data\n",
        "\n",
        "df \u003d pd.concat([pd.read_csv(f\u0027https://storage.googleapis.com/kubeflow-examples/code_search/raw_data/00000000000{i}.csv\u0027) \\\n",
        "                for i in range(10)])\n",
        "\n",
        "df[\u0027nwo\u0027] \u003d df[\u0027repo_path\u0027].apply(lambda r: r.split()[0])\n",
        "df[\u0027path\u0027] \u003d df[\u0027repo_path\u0027].apply(lambda r: r.split()[1])\n",
        "df.drop(columns\u003d[\u0027repo_path\u0027], inplace\u003dTrue)\n",
        "df \u003d df[[\u0027nwo\u0027, \u0027path\u0027, \u0027content\u0027]]\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1241664, 3)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Inspect shape of the raw data\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Functions to parse data and tokenize\n",
        "\n",
        "Our goal is to parse the python files into (code, docstring) pairs.  Fortunately, the standard library in python comes with the wonderful [ast](https://docs.python.org/3.6/library/ast.html) module which helps us extract code from files as well as extract docstrings.  \n",
        "\n",
        "We also use the [astor](http://astor.readthedocs.io/en/latest/) library to strip the code of comments by doing a round trip of converting the code to an [AST](https://en.wikipedia.org/wiki/Abstract_syntax_tree) and then from AST back to code. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": [
        "from feature_extractor import get_function_docstring_pairs_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "The below convience function `apply_parallel` parses the code in parallel using process based threading.  Adjust the `cpu_cores` parameter accordingly to your system resources!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": [
        "pairs \u003d flattenlist(apply_parallel(get_function_docstring_pairs_list, df.content.tolist(), cpu_cores\u003d16))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\u003cdiv\u003e\n",
              "\u003cstyle scoped\u003e\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\u003c/style\u003e\n",
              "\u003ctable border\u003d\"1\" class\u003d\"dataframe\"\u003e\n",
              "  \u003cthead\u003e\n",
              "    \u003ctr style\u003d\"text-align: right;\"\u003e\n",
              "      \u003cth\u003e\u003c/th\u003e\n",
              "      \u003cth\u003enwo\u003c/th\u003e\n",
              "      \u003cth\u003epath\u003c/th\u003e\n",
              "      \u003cth\u003econtent\u003c/th\u003e\n",
              "      \u003cth\u003epairs\u003c/th\u003e\n",
              "    \u003c/tr\u003e\n",
              "  \u003c/thead\u003e\n",
              "  \u003ctbody\u003e\n",
              "    \u003ctr\u003e\n",
              "      \u003cth\u003e0\u003c/th\u003e\n",
              "      \u003ctd\u003efnl/libfnl\u003c/td\u003e\n",
              "      \u003ctd\u003esrc/fnl/nlp/dictionary.py\u003c/td\u003e\n",
              "      \u003ctd\u003e\"\"\"\\n.. py:module:: fnl.text.dictionary\\n   :s...\u003c/td\u003e\n",
              "      \u003ctd\u003e[(__init__, 19, def __init__(self, *leafs, **e...\u003c/td\u003e\n",
              "    \u003c/tr\u003e\n",
              "    \u003ctr\u003e\n",
              "      \u003cth\u003e1\u003c/th\u003e\n",
              "      \u003ctd\u003eKivApple/mcu-info-util\u003c/td\u003e\n",
              "      \u003ctd\u003emcu_info_util/linker_script.py\u003c/td\u003e\n",
              "      \u003ctd\u003efrom six import iteritems\\n\\n\\ndef generate(op...\u003c/td\u003e\n",
              "      \u003ctd\u003e[(generate, 4, def generate(options, filename\u003d...\u003c/td\u003e\n",
              "    \u003c/tr\u003e\n",
              "    \u003ctr\u003e\n",
              "      \u003cth\u003e2\u003c/th\u003e\n",
              "      \u003ctd\u003eYelp/pyleus\u003c/td\u003e\n",
              "      \u003ctd\u003eexamples/bandwith_monitoring/bandwith_monitori...\u003c/td\u003e\n",
              "      \u003ctd\u003efrom __future__ import absolute_import, divisi...\u003c/td\u003e\n",
              "      \u003ctd\u003e[(__init__, 18, def __init__(self, size):\\n   ...\u003c/td\u003e\n",
              "    \u003c/tr\u003e\n",
              "    \u003ctr\u003e\n",
              "      \u003cth\u003e3\u003c/th\u003e\n",
              "      \u003ctd\u003ejhuapl-boss/boss-manage\u003c/td\u003e\n",
              "      \u003ctd\u003ebin/bearer_token.py\u003c/td\u003e\n",
              "      \u003ctd\u003e#!/usr/bin/env python3\\n\\n# Copyright 2016 The...\u003c/td\u003e\n",
              "      \u003ctd\u003e[(request, 46, def request(url, params\u003dNone, h...\u003c/td\u003e\n",
              "    \u003c/tr\u003e\n",
              "    \u003ctr\u003e\n",
              "      \u003cth\u003e4\u003c/th\u003e\n",
              "      \u003ctd\u003edjfroofy/beatlounge\u003c/td\u003e\n",
              "      \u003ctd\u003ebl/orchestra/base.py\u003c/td\u003e\n",
              "      \u003ctd\u003efrom itertools import cycle\\n\\nfrom twisted.py...\u003c/td\u003e\n",
              "      \u003ctd\u003e[(schedule, 149, def schedule(time, func, args...\u003c/td\u003e\n",
              "    \u003c/tr\u003e\n",
              "  \u003c/tbody\u003e\n",
              "\u003c/table\u003e\n",
              "\u003c/div\u003e"
            ],
            "text/plain": [
              "                       nwo                                               path  \\\n",
              "0               fnl/libfnl                          src/fnl/nlp/dictionary.py   \n",
              "1   KivApple/mcu-info-util                     mcu_info_util/linker_script.py   \n",
              "2              Yelp/pyleus  examples/bandwith_monitoring/bandwith_monitori...   \n",
              "3  jhuapl-boss/boss-manage                                bin/bearer_token.py   \n",
              "4      djfroofy/beatlounge                               bl/orchestra/base.py   \n",
              "\n",
              "                                             content  \\\n",
              "0  \"\"\"\\n.. py:module:: fnl.text.dictionary\\n   :s...   \n",
              "1  from six import iteritems\\n\\n\\ndef generate(op...   \n",
              "2  from __future__ import absolute_import, divisi...   \n",
              "3  #!/usr/bin/env python3\\n\\n# Copyright 2016 The...   \n",
              "4  from itertools import cycle\\n\\nfrom twisted.py...   \n",
              "\n",
              "                                               pairs  \n",
              "0  [(__init__, 19, def __init__(self, *leafs, **e...  \n",
              "1  [(generate, 4, def generate(options, filename\u003d...  \n",
              "2  [(__init__, 18, def __init__(self, size):\\n   ...  \n",
              "3  [(request, 46, def request(url, params\u003dNone, h...  \n",
              "4  [(schedule, 149, def schedule(time, func, args...  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "assert len(pairs) \u003d\u003d df.shape[0], f\u0027Row count mismatch. `df` has {df.shape[0]:,} rows; `pairs` has {len(pairs):,} rows.\u0027\n",
        "df[\u0027pairs\u0027] \u003d pairs\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Flatten code, docstring pairs and extract meta-data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "Flatten (code, docstring) pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "df \u003d df.set_index([\u0027nwo\u0027, \u0027path\u0027])[\u0027pairs\u0027].apply(pd.Series).stack()\n",
        "df \u003d df.reset_index()\n",
        "df.columns \u003d [\u0027nwo\u0027, \u0027path\u0027, \u0027_\u0027, \u0027pair\u0027]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "Extract meta-data and format dataframe.  \n",
        "\n",
        "We have not optimized this code.  Pull requests are welcome!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\u003cdiv\u003e\n",
              "\u003cstyle scoped\u003e\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\u003c/style\u003e\n",
              "\u003ctable border\u003d\"1\" class\u003d\"dataframe\"\u003e\n",
              "  \u003cthead\u003e\n",
              "    \u003ctr style\u003d\"text-align: right;\"\u003e\n",
              "      \u003cth\u003e\u003c/th\u003e\n",
              "      \u003cth\u003enwo\u003c/th\u003e\n",
              "      \u003cth\u003epath\u003c/th\u003e\n",
              "      \u003cth\u003efunction_name\u003c/th\u003e\n",
              "      \u003cth\u003elineno\u003c/th\u003e\n",
              "      \u003cth\u003eoriginal_function\u003c/th\u003e\n",
              "      \u003cth\u003efunction_tokens\u003c/th\u003e\n",
              "      \u003cth\u003edocstring_tokens\u003c/th\u003e\n",
              "      \u003cth\u003eapi_sequence\u003c/th\u003e\n",
              "      \u003cth\u003etokenized_function_name\u003c/th\u003e\n",
              "    \u003c/tr\u003e\n",
              "  \u003c/thead\u003e\n",
              "  \u003ctbody\u003e\n",
              "    \u003ctr\u003e\n",
              "      \u003cth\u003e0\u003c/th\u003e\n",
              "      \u003ctd\u003efnl/libfnl\u003c/td\u003e\n",
              "      \u003ctd\u003esrc/fnl/nlp/dictionary.py\u003c/td\u003e\n",
              "      \u003ctd\u003e__init__\u003c/td\u003e\n",
              "      \u003ctd\u003e19\u003c/td\u003e\n",
              "      \u003ctd\u003edef __init__(self, *leafs, **edges):\\n    self...\u003c/td\u003e\n",
              "      \u003ctd\u003edef __init__ self leafs edges self edges edges...\u003c/td\u003e\n",
              "      \u003ctd\u003e\u003c/td\u003e\n",
              "      \u003ctd\u003eself edges edges self leafs sorted leafs\u003c/td\u003e\n",
              "      \u003ctd\u003einit\u003c/td\u003e\n",
              "    \u003c/tr\u003e\n",
              "    \u003ctr\u003e\n",
              "      \u003cth\u003e1\u003c/th\u003e\n",
              "      \u003ctd\u003efnl/libfnl\u003c/td\u003e\n",
              "      \u003ctd\u003esrc/fnl/nlp/dictionary.py\u003c/td\u003e\n",
              "      \u003ctd\u003e__eq__\u003c/td\u003e\n",
              "      \u003ctd\u003e23\u003c/td\u003e\n",
              "      \u003ctd\u003edef __eq__(self, other):\\n    if isinstance(ot...\u003c/td\u003e\n",
              "      \u003ctd\u003edef __eq__ self other if isinstance other Node...\u003c/td\u003e\n",
              "      \u003ctd\u003e\u003c/td\u003e\n",
              "      \u003ctd\u003eif isinstance other node return id self id oth...\u003c/td\u003e\n",
              "      \u003ctd\u003eeq\u003c/td\u003e\n",
              "    \u003c/tr\u003e\n",
              "    \u003ctr\u003e\n",
              "      \u003cth\u003e2\u003c/th\u003e\n",
              "      \u003ctd\u003efnl/libfnl\u003c/td\u003e\n",
              "      \u003ctd\u003esrc/fnl/nlp/dictionary.py\u003c/td\u003e\n",
              "      \u003ctd\u003e__repr__\u003c/td\u003e\n",
              "      \u003ctd\u003e29\u003c/td\u003e\n",
              "      \u003ctd\u003edef __repr__(self):\\n    return \u0027Node\u0026lt;leafs\u003d{}...\u003c/td\u003e\n",
              "      \u003ctd\u003edef __repr__ self return Node leafs edges form...\u003c/td\u003e\n",
              "      \u003ctd\u003e\u003c/td\u003e\n",
              "      \u003ctd\u003ereturn node\u0026lt;leafs\u003d{}, edges\u003d{}\u0026gt; format self le...\u003c/td\u003e\n",
              "      \u003ctd\u003erepr\u003c/td\u003e\n",
              "    \u003c/tr\u003e\n",
              "    \u003ctr\u003e\n",
              "      \u003cth\u003e3\u003c/th\u003e\n",
              "      \u003ctd\u003efnl/libfnl\u003c/td\u003e\n",
              "      \u003ctd\u003esrc/fnl/nlp/dictionary.py\u003c/td\u003e\n",
              "      \u003ctd\u003ecreate_or_get\u003c/td\u003e\n",
              "      \u003ctd\u003e32\u003c/td\u003e\n",
              "      \u003ctd\u003edef createOrGet(self, token):\\n    \"\"\"\\n\\t\\tCr...\u003c/td\u003e\n",
              "      \u003ctd\u003edef createOrGet self token if token in self ed...\u003c/td\u003e\n",
              "      \u003ctd\u003ecreate or get the node pointed to by ` token `...\u003c/td\u003e\n",
              "      \u003ctd\u003eif token self edges node self edges token else...\u003c/td\u003e\n",
              "      \u003ctd\u003ecreate or get\u003c/td\u003e\n",
              "    \u003c/tr\u003e\n",
              "    \u003ctr\u003e\n",
              "      \u003cth\u003e4\u003c/th\u003e\n",
              "      \u003ctd\u003efnl/libfnl\u003c/td\u003e\n",
              "      \u003ctd\u003esrc/fnl/nlp/dictionary.py\u003c/td\u003e\n",
              "      \u003ctd\u003eset_leaf\u003c/td\u003e\n",
              "      \u003ctd\u003e47\u003c/td\u003e\n",
              "      \u003ctd\u003edef setLeaf(self, key, order):\\n    \"\"\"\\n\\t\\tS...\u003c/td\u003e\n",
              "      \u003ctd\u003edef setLeaf self key order self leafs append o...\u003c/td\u003e\n",
              "      \u003ctd\u003estore the ` key ` as a leaf of this node at po...\u003c/td\u003e\n",
              "      \u003ctd\u003eself leafs append order key self leafs sorted ...\u003c/td\u003e\n",
              "      \u003ctd\u003eset leaf\u003c/td\u003e\n",
              "    \u003c/tr\u003e\n",
              "  \u003c/tbody\u003e\n",
              "\u003c/table\u003e\n",
              "\u003c/div\u003e"
            ],
            "text/plain": [
              "          nwo                       path  function_name  lineno  \\\n",
              "0  fnl/libfnl  src/fnl/nlp/dictionary.py       __init__      19   \n",
              "1  fnl/libfnl  src/fnl/nlp/dictionary.py         __eq__      23   \n",
              "2  fnl/libfnl  src/fnl/nlp/dictionary.py       __repr__      29   \n",
              "3  fnl/libfnl  src/fnl/nlp/dictionary.py  create_or_get      32   \n",
              "4  fnl/libfnl  src/fnl/nlp/dictionary.py       set_leaf      47   \n",
              "\n",
              "                                   original_function  \\\n",
              "0  def __init__(self, *leafs, **edges):\\n    self...   \n",
              "1  def __eq__(self, other):\\n    if isinstance(ot...   \n",
              "2  def __repr__(self):\\n    return \u0027Node\u003cleafs\u003d{}...   \n",
              "3  def createOrGet(self, token):\\n    \"\"\"\\n\\t\\tCr...   \n",
              "4  def setLeaf(self, key, order):\\n    \"\"\"\\n\\t\\tS...   \n",
              "\n",
              "                                     function_tokens  \\\n",
              "0  def __init__ self leafs edges self edges edges...   \n",
              "1  def __eq__ self other if isinstance other Node...   \n",
              "2  def __repr__ self return Node leafs edges form...   \n",
              "3  def createOrGet self token if token in self ed...   \n",
              "4  def setLeaf self key order self leafs append o...   \n",
              "\n",
              "                                    docstring_tokens  \\\n",
              "0                                                      \n",
              "1                                                      \n",
              "2                                                      \n",
              "3  create or get the node pointed to by ` token `...   \n",
              "4  store the ` key ` as a leaf of this node at po...   \n",
              "\n",
              "                                        api_sequence tokenized_function_name  \n",
              "0           self edges edges self leafs sorted leafs                    init  \n",
              "1  if isinstance other node return id self id oth...                      eq  \n",
              "2  return node\u003cleafs\u003d{}, edges\u003d{}\u003e format self le...                    repr  \n",
              "3  if token self edges node self edges token else...           create or get  \n",
              "4  self leafs append order key self leafs sorted ...                set leaf  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# %%time\n",
        "df[\u0027function_name\u0027] \u003d df[\u0027pair\u0027].apply(lambda p: p[0])\n",
        "df[\u0027lineno\u0027] \u003d df[\u0027pair\u0027].apply(lambda p: p[1])\n",
        "df[\u0027original_function\u0027] \u003d df[\u0027pair\u0027].apply(lambda p: p[2])\n",
        "df[\u0027function_tokens\u0027] \u003d df[\u0027pair\u0027].apply(lambda p: p[3])\n",
        "df[\u0027docstring_tokens\u0027] \u003d df[\u0027pair\u0027].apply(lambda p: p[4])\n",
        "df[\u0027api_sequence\u0027] \u003d df[\u0027pair\u0027].apply(lambda p:p[5])\n",
        "df[\u0027tokenized_function_name\u0027] \u003d df[\u0027pair\u0027].apply(lambda p: p[6])\n",
        "df \u003d df[[\u0027nwo\u0027, \u0027path\u0027, \u0027function_name\u0027, \u0027lineno\u0027, \u0027original_function\u0027, \u0027function_tokens\u0027, \u0027docstring_tokens\u0027, \u0027api_sequence\u0027, \u0027tokenized_function_name\u0027]]\n",
        "df[\u0027url\u0027] \u003d df[[\u0027nwo\u0027, \u0027path\u0027, \u0027lineno\u0027]].apply(lambda x: \u0027https://github.com/{}/blob/master/{}#L{}\u0027.format(x[0], x[1], x[2]), axis\u003d1)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Remove Duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removed 1,197,585 duplicate rows\n"
          ]
        }
      ],
      "source": [
        "# remove observations where the same function appears more than once\n",
        "before_dedup \u003d len(df)\n",
        "df \u003d df.drop_duplicates([\u0027original_function\u0027, \u0027function_tokens\u0027])\n",
        "after_dedup \u003d len(df)\n",
        "\n",
        "print(f\u0027Removed {before_dedup - after_dedup:,} duplicate rows\u0027)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "pycharm": {},
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5403896, 9)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "### Serialize the dataframe for later use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": "import pandas as pd\ndf.to_pickle(\u0027./data/dataframe_processed.pkl\u0027)"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}